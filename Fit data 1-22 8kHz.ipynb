{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fit_data_1_22_common import *\n",
    "\n",
    "pl.style.use('fivethirtyeight')\n",
    "\n",
    "#mpl.rc('figure', figsize=(10,8))\n",
    "mpl.rcParams['axes.facecolor']='white'  \n",
    "mpl.rcParams['figure.facecolor'] = '1'\n",
    "\n",
    "from optim import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact, interactive, fixed, interact_manual\n",
    "import ipywidgets as widgets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common for all CFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#see fit_data_1_22_common.py\n",
    "\n",
    "#plot_main_CAPs()\n",
    "#plot_CAP_with_window()\n",
    "#plot_CAP_w_wo_filter()\n",
    "\n",
    "#NB: the plots below depend on the choice of the signal used for the estimation of ur\n",
    "#plot_raw_excitation_deconv()\n",
    "#plot_figures_narrowband_analysis()\n",
    "#plot_figures_narrowband_analysis_deconv()\n",
    "\n",
    "#plot_estimated_latencies_deconv()\n",
    "#plot_estimated_latencies_deconv()\n",
    "#plot_latencies_fit()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8kHz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "first estimation I/O curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cap=[]\n",
    "rms=[]\n",
    "masker_list=['2_notch8000_bw2300_55dB',\n",
    " '3_notch8000_bw2300_50dB',\n",
    " '4_notch8000_bw2300_45dB',\n",
    " '5_notch8000_bw2300_40dB',\n",
    " '6_notch8000_bw2300_35dB',\n",
    " '7_notch8000_bw2300_32dB',\n",
    " '7_notch8000_bw2300_29dB',\n",
    " '8_notch8000_bw2300_26dB',\n",
    " '9_notch8000_bw2300_23dB']   #, 'broadband_noise'\n",
    "for masker in masker_list:\n",
    "    sig=capData.get_signal_by_name(masker)\n",
    "    sig=process_signal(sig)\n",
    "    broadband_sig_trunc=process_signal(broadband2)\n",
    "    \n",
    "    #REF broadband\n",
    "    cap.append(np.max(sig-broadband_sig_trunc)-np.min(sig-broadband_sig_trunc))\n",
    "    #rms.append(np.std(sig-broadband_sig_trunc))\n",
    "    \n",
    "    #cap.append(np.max(sig)-np.min(sig))\n",
    "    #rms.append(np.std(sig-broadband_sig_trunc))\n",
    "    pl.plot(t2, sig-broadband_sig_trunc, label=masker)\n",
    "\n",
    "\n",
    "pl.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "pl.show()\n",
    "\n",
    "pl.figure(figsize=(8, 6))\n",
    "\n",
    "attns=-np.array([55, 50, 45,40,35,32,29,26,23])   # 20])\n",
    "pl.plot(attns, cap, '+', label='max-min')\n",
    "\n",
    "#pl.plot(-np.array([55,50,45,40,37,34,31,28,25,22]), np.array(rms)*10, label='rms x10')\n",
    "pl.legend()\n",
    "pl.xlabel('Notch attenuation')\n",
    "pl.ylabel('Amplitude difference')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sigm=SigmoidIOFunc(0, 0)\n",
    "#maskamount=1-(  (cap-np.amin(cap)) /np.amax(cap-np.amin(cap)) )\n",
    "maskamount=1-(cap/np.amax(cap)) \n",
    "\n",
    "I_pts=I0+attns\n",
    "#sigm.fit_data(I_pts, maskamount, set_mmax=True)\n",
    "\n",
    "#HACK enforce masking=100% at attn20\n",
    "#sigm.mmax.data*=1/sigm(I0-20)\n",
    "\n",
    "sigm.fit_data(I_pts, maskamount, constrained_at_Iref=True, Iref=I0-20)\n",
    "\n",
    "I=np.linspace(-30, 20)\n",
    "pl.plot(I, sigm(torch.tensor(I)), label='fit sigm')\n",
    "pl.xlabel('Power spectral density (dB)')\n",
    "\n",
    "pl.plot(I_pts, maskamount, '+', markersize=10, markeredgewidth=3)\n",
    "\n",
    "pl.plot(I0-20, 1, '+', markersize=10, markeredgewidth=3, color='purple')\n",
    "\n",
    "pl.ylabel('masking (max: broadband)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wb_cdf=WeibullCDF_IOFunc()\n",
    "\n",
    "wb_cdf.fit_data(I_pts, maskamount, constrained_at_Iref=True, Iref=I0-20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.plot(I, sigm(torch.tensor(I)), label='fit sigm')\n",
    "pl.plot(I, wb_cdf(torch.tensor(I)), label='fit sigm')\n",
    "pl.xlabel('Power spectral density (dB)')\n",
    "\n",
    "pl.plot(I_pts, maskamount, '+', markersize=10, markeredgewidth=3)\n",
    "\n",
    "pl.plot(I0-20, 1, '+', markersize=10, markeredgewidth=3, color='purple')\n",
    "\n",
    "pl.ylabel('masking (max: broadband)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntch_maskerNames, ntch_maskingConds, ntch_signals =capData.get_batch_re('.*notch8000_bw2300')\n",
    "ntch_maskingConds.set_amp0_dB(I0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HACK pad maskers >12e3 to avoid issues with latencies (equivalent to taking the difference\n",
    "#  excitations of maskers - excitation 'broadband noise')\n",
    "ntch_maskingConds.pad_maskers(f_thr=11000, f_max=1e5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gauss_sigma=(1.5e-4)/(t2[1]-t2[0])\n",
    "ntch_signals_proc=process_signal2(ntch_signals, gauss_sigma=gauss_sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test\n",
    "\n",
    "for maskerName, sig in zip(ntch_maskerNames, ntch_signals_proc):\n",
    "    pl.plot(t2, sig, label=maskerName)\n",
    "\n",
    "pl.legend(bbox_to_anchor=(1.05, 1), loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# estimation ur\n",
    "\n",
    "sig=capData.get_signal_by_name('4_notch8000_bw2300_45dB')\n",
    "sig2=process_signal(sig)\n",
    "\n",
    "pl.plot((t2-3e-3)*1e3, sig2-broadband_proc)\n",
    "\n",
    "#pl.plot(t2*1e3, sig2bis-broadband_proc)\n",
    "\n",
    "t_shift=6e-3-3e-3 #excitation coincides with CM\n",
    "\n",
    "ur0=sig2-broadband_proc\n",
    "ur0=np.roll(ur0,  -int(t_shift*48828) )\n",
    "pl.plot((t2-3e-3)*1e3, ur0)\n",
    "#pl.xlim([4,6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#latencies model\n",
    "\n",
    "#lat_model=lat_above4k\n",
    "#lat_model=lat\n",
    "\n",
    "#lat_model=PowerLawLatencies.shift(lat_model, 6e-3-1e-3)   #t0: start CM-1ms\n",
    "\n",
    "#HACK as latencies are very small (sampling issues), manual dilatation\n",
    "\n",
    "lat_model=PowerLawLatencies.fromPts(0.0057, 9500, 0.0062, 6000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test single lat model\n",
    "singleLat=True\n",
    "if singleLat:\n",
    "    f_min=4000\n",
    "    f_max=12000\n",
    "    lat_model = SingleLatency(6e-3, f_min=f_min, f_max=f_max)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if singleLat:\n",
    "    m=400\n",
    "    E0=1/2*np.ones((m,))\n",
    "    \n",
    "    pl.plot(np.linspace(f_min*1e-3, f_max*1e-3, m), E0)\n",
    "    pl.xlabel('Frequency (kHz)')\n",
    "    pl.ylabel('Init raw excitation')\n",
    "else:\n",
    "    m=72\n",
    "    E0_temp=sg.windows.tukey(m, alpha=0.5) \n",
    "    E0=np.zeros_like(t2)\n",
    "    ind_begin=int((t_shift-1e-3)*48828)\n",
    "    ind_end=int((t_shift-1e-3)*48828)+m\n",
    "    E0[ind_begin:ind_end]=E0_temp\n",
    "\n",
    "    pl.plot(t2*1e3, E0)\n",
    "    pl.title('Init raw excitation')\n",
    "    pl.xlabel('t (ms)')\n",
    "    pl.ylabel('Amp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotLatencies(lat_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E=ExcitationPatterns(t2, E0)  #no non-maskable part\n",
    "#E=ExcitationPatterns(t2, E_temp.E0_maskable)\n",
    "\n",
    "BW10_0=1000\n",
    "BW10_0Func=constant_BW10(BW10_0, requires_grad=False)\n",
    "\n",
    "E.set_masking_model(lat_model, BW10_0Func, ntch_maskingConds, sigm)\n",
    "#E.set_masking_model(lat_model, BW10_0Func, ntch_maskingConds, wb_cdf)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pl.figure(figsize=(10,20))\n",
    "plotMaskingAmountExcitations(BW10_0Func, ntch_maskingConds, sigm)\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.figure(figsize=(10,20))\n",
    "plotExcitationPatterns(E, plot_raw_excitation=True) # ylim_top=1\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "maskAmounts, excs = E.get_tensors() \n",
    "\n",
    "for i in range(5):\n",
    "    pl.plot(E.t*1e3, maskAmounts[i], label=ntch_maskerNames[i])\n",
    "pl.xlim([3,6])\n",
    "pl.ylim([0,1])\n",
    "pl.legend(bbox_to_anchor=(1.05, 1), loc='upper left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#estimation ur\n",
    "\n",
    "maskAmounts, excs = E.get_tensors() \n",
    "\n",
    "nb_steps=20\n",
    "alpha=np.linspace(0.5, 0.05, nb_steps)\n",
    "\n",
    "EPs_fft=np.fft.rfft(excs, axis=1)\n",
    "CAPs_fft=np.fft.rfft(ntch_signals_proc, axis=1)\n",
    "#u1_mat=np.tile(ur0, (ntch_maskingConds.n_conditions, 1))\n",
    "u1_mat=np.zeros_like(ntch_signals_proc)\n",
    "filter_mat  = (t2>7.5e-3)+(t2<3.2e-3)\n",
    "filter_mat=np.tile(filter_mat, (ntch_maskingConds.n_conditions, 1))\n",
    "#filter_mat=np.zeros_like(ntch_signals_proc, dtype=bool)\n",
    "#proj_fft=E.get_projector_fft()\n",
    "\n",
    "weights=np.sqrt(np.sum(excs.clone().detach().numpy()**2, axis=1))\n",
    "for i in range(1, nb_steps+1):\n",
    "    du=deconv_newton_step(u1_mat, EPs_fft, CAPs_fft, eps_ridge=0)   #TODO proj_fft\n",
    "    #du=deconv_grad(u1_mat, EPs_fft, CAPs_fft)\n",
    "    \n",
    "    u1_mat-=alpha[i-1]*du\n",
    "    #proj 1 \n",
    "    u1_mat[filter_mat]=np.zeros_like(u1_mat[filter_mat])\n",
    "    #proj 2\n",
    "\n",
    "    #u1_mat_mean=np.mean(u1_mat, axis=0)[None, :]\n",
    "    \n",
    "    \n",
    "    #HACK waiting for proj_fft\n",
    "    u1_mat_mean=np.average(u1_mat, axis=0, weights=weights)[None, :]\n",
    "    u1_mat=np.repeat(u1_mat_mean, ntch_maskingConds.n_conditions, axis=0)\n",
    "     \n",
    "    '''\n",
    "    for i in range(5):\n",
    "            pl.figure()\n",
    "            name=ntch_maskerNames[i]\n",
    "            pl.plot(u1_mat[i], label=name, color=f'C{i}')\n",
    "            #pl.plot( np.abs(EPs_fft[i]))\n",
    "            pl.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "    '''\n",
    "    \n",
    "    if i==nb_steps:\n",
    "        pl.figure()\n",
    "        pl.title(f'Step {i} (deconv + proj)')\n",
    "        #pl.plot(t, u0, label='u0 (truth)')\n",
    "        pl.plot(t2, u1_mat[0], label='u0 (estimated)')\n",
    "        pl.legend()\n",
    "        #pl.savefig('ur_8kHz_Q395.svg')\n",
    "        pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test estimation raw excitation pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fln_list=['1_hp_10000Hz', '2_hp_9000Hz', '3_hp_8000Hz', '4_hp_7000Hz', '5_hp_6000Hz', '6_hp_5000Hz',\n",
    "           '6_notch8000_bw2300_35dB', '8_notch8000_bw2300_26dB',\n",
    "'1-notch7600_bw1100.json', '2-notch7800_bw1300.json',\n",
    "'3-notch8000_bw1400.json',\n",
    "'4-notch8200_bw1300.json',\n",
    "'5-notch8200_bw1500.json',\n",
    "'6-notch7900_bw1600.json',\n",
    "'7-notch8100_bw1200.json',         \n",
    "'6_notch6000_bw2000_35dB', '9_notch6000_bw2000_26dB',\n",
    "'2-notch6200_bw1000.json', '3-notch6000_bw1100.json', '9-notch6300_bw1100.json'\n",
    "]\n",
    "masker_list=[st.replace('-', '_').replace('.json', '') for st in fln_list]\n",
    "\n",
    "reg_exp=')|('.join(masker_list)\n",
    "reg_exp='('+reg_exp+')'\n",
    "vfreq_maskerNames, vfreq_maskingConds, vfreq_signals =capData.get_batch_re(reg_exp)\n",
    "vfreq_signals_proc=process_signal2(vfreq_signals, gauss_sigma=gauss_sigma)\n",
    "vfreq_maskingConds.set_amp0_dB(I0)\n",
    "vfreq_maskingConds.pad_maskers(f_thr=11000, f_max=1e5)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signals_proc=vfreq_signals_proc\n",
    "maskingConds=vfreq_maskingConds\n",
    "\n",
    "E_temp=ExcitationPatterns.copyRaw(E, requires_grad=True)\n",
    "\n",
    "E_temp.set_masking_model(lat_model, BW10_0Func, maskingConds, sigm)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nb_steps=5\n",
    "alpha=50\n",
    "n_dim=7 #projection of gradient on n_dim first dimensions (Fourier basis)\n",
    "\n",
    "alpha_dic={E_temp.E0_maskable: alpha}\n",
    "optim_steps(E_temp, u1_mat[0], signals_proc, alpha_dic, \n",
    "            nb_steps=nb_steps, n_dim_E0=n_dim,plot_graphs=True )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E.E0_maskable.data=E_temp.E0_maskable.data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reestimation I/O curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exc_max=[]\n",
    "exc_rms=[]\n",
    "attns_=[]\n",
    "\n",
    "amps=ntch_maskingConds.amp_list[1]\n",
    "for i in range(len(ntch_maskerNames)):\n",
    "    name=ntch_maskerNames[i]\n",
    "    sig=ntch_signals_proc[i]\n",
    "    \n",
    "    #pl.plot(t2*1e3, excs[i], label=name, color=f'C{i}')\n",
    "\n",
    "    E_i=np.zeros_like(sig)\n",
    "    E_i=deconv_newton(E_i, sig, ur0=u1_mat[0], alpha=1, nb_steps=20, t0=5.7e-3, t1=6.5e-3, eps_ridge=0.1)  #double peak?\n",
    "    \n",
    "    \n",
    "    attn_=20*np.log10(amps[i])\n",
    "    \n",
    "    #HACK remove outlier\n",
    "    #if not (np.abs(attn_-65)<2):\n",
    "    if True:\n",
    "        exc_max.append(np.amax(E_i))\n",
    "\n",
    "        exc_rms.append(np.sqrt(np.sum(E_i**2) ))\n",
    "        attns_.append(attn_)\n",
    "    pl.plot(t2*1e3, E_i, label=name, color=f'C{i}')\n",
    "    \n",
    "pl.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "\n",
    "\n",
    "pl.figure()\n",
    "pl.plot(attns_, exc_max, '+')\n",
    "                   \n",
    "pl.plot(attns_, np.array(exc_rms)*0.2, '+')\n",
    "pl.xlabel('Intensity (dB)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reestimation I-0 curve: \n",
    "\n",
    "I_pts=np.array(attns_)  #I0 already in masking cond\n",
    "\n",
    "sigm=SigmoidIOFunc(0, 0)\n",
    "exc_rms=np.array(exc_rms)\n",
    "maskamount=1- (exc_rms)/np.amax(exc_rms) \n",
    "\n",
    "\n",
    "#add broadband condition\n",
    "#attns_.append(80)\n",
    "#ma_list=list(maskamount)\n",
    "#ma_list.append(1.)\n",
    "#maskamount=np.array(ma_list)\n",
    "\n",
    "#sigm.fit_data(np.array(attns_), maskamount, set_mmax=True)\n",
    "\n",
    "#HACK enforce masking=100% at attn20\n",
    "#sigm.mmax.data*=1/sigm(I0-20)\n",
    "\n",
    "sigm.fit_data(I_pts, maskamount, constrained_at_Iref=True, Iref=I0-20)\n",
    "\n",
    "wb_cdf=WeibullCDF_IOFunc()\n",
    "wb_cdf.fit_data(I_pts, maskamount, constrained_at_Iref=True, Iref=I0-20)\n",
    "\n",
    "I=np.linspace(-30, 20)\n",
    "pl.plot(I, sigm(torch.tensor(I)), label='fit sigm')\n",
    "pl.plot(I, wb_cdf(torch.tensor(I)), label='fit wb cdf')\n",
    "\n",
    "\n",
    "pl.suptitle('Amount of masking in response to broadband noise')\n",
    "pl.title(' (as estimated with the notch method)', fontsize=10)\n",
    "pl.xlabel('Power spectral density (dB)')\n",
    "\n",
    "pl.plot(I_pts, maskamount, '+', markersize=10, markeredgewidth=3)\n",
    "pl.plot(I0-20, 1, '+', markersize=10, markeredgewidth=3, color='purple')\n",
    "\n",
    "pl.ylabel('masking (ref max: no notch)')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "masker_name='4_notch8200_bw1300'\n",
    "sig=capData.get_signal_by_name(masker_name)\n",
    "sig=process_signal2(sig)\n",
    "#pl.plot(t2*1e3, excs[i], label=name, color=f'C{i}')\n",
    "\n",
    "E_i=np.zeros_like(sig)\n",
    "E_i=deconv_newton(E_i, sig, ur0=u1_mat[0], alpha=0.1, nb_steps=20, t0=5.7e-3, t1=6.5e-3, eps_ridge=0.1)  #double peak?\n",
    "\n",
    "pl.plot(t2*1e3, E_i, label=masker_name, color=f'C{i}')\n",
    "\n",
    "pl.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model\n",
    "u1=u1_mat[0]\n",
    "pl.figure(figsize=(12,20))\n",
    "ax_list=plotSimulatedCAPs(E, u1, ylim=[-0.01, 0.01], max_plots=10)\n",
    "plotSimulatedCAPs(E, CAParray=ntch_signals_proc, axlist=ax_list, max_plots=10)\n",
    "pl.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fln_list=['1-notch7600_bw1100.json',\n",
    "'2-notch7800_bw1300.json',\n",
    "'3-notch8000_bw1400.json',\n",
    "'4-notch8200_bw1300.json',\n",
    "'5-notch8200_bw1500.json',\n",
    "'6-notch7900_bw1600.json',\n",
    "'7-notch8100_bw1200.json']\n",
    "masker_list=[st.replace('-', '_').replace('.json', '') for st in fln_list]\n",
    "reg_exp=')|('.join(masker_list)\n",
    "reg_exp='('+reg_exp+')'\n",
    "vbw_maskerNames, vbw_maskingConds, vbw_signals =capData.get_batch_re(reg_exp)\n",
    "vbw_signals_proc=process_signal2(vbw_signals, gauss_sigma=gauss_sigma)\n",
    "vbw_maskingConds.set_amp0_dB(I0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#HACK\n",
    "vbw_maskingConds.pad_maskers(f_thr=11000, f_max=1e5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E2=ExcitationPatterns.copyRaw(E)  #no non-maskable part\n",
    "BW10_0TestFunc=constant_BW10(2300, requires_grad=False)\n",
    "\n",
    "#E2.set_masking_model(lat_model, BW10_0TestFunc, vbw_maskingConds, sigm)\n",
    "E2.set_masking_model(lat_model, BW10_0TestFunc, vbw_maskingConds, wb_cdf2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model\n",
    "u1=u1_mat[0]\n",
    "pl.figure(figsize=(10,14))\n",
    "with torch.no_grad():\n",
    "    ax_list=plotSimulatedCAPs(E2, u1, ylim=[-0.01, 0.01])\n",
    "    plotSimulatedCAPs(E2, CAParray=vbw_signals_proc, axlist=ax_list)\n",
    "pl.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bw_arr=np.linspace(500, 4000, num= ((4000-500)//50+1) )\n",
    "sigs_ref=vbw_signals_proc\n",
    "errs=[]\n",
    "for bw in bw_arr:\n",
    "\n",
    "    BW10_0TestFunc=constant_BW10(bw, requires_grad=False)\n",
    "    E2.set_masking_model(lat_model, BW10_0TestFunc, vbw_maskingConds, sigm)\n",
    "    #E2.set_masking_model(lat_model, BW10_0TestFunc, vbw_maskingConds, wb_cdf2)\n",
    "    \n",
    "    excs = E2.get_tensor() \n",
    "    maskingConditions = E2.maskingConditions\n",
    "    err=0\n",
    "    for i, exc in zip(range(maskingConditions.n_conditions), excs):\n",
    "        exc_np = exc.detach().numpy()\n",
    "        CAP=np.convolve(exc_np, u1, mode='full')\n",
    "        t=E.t.numpy()\n",
    "        CAP=CAP[0:len(E2.t)]\n",
    "        err+=np.sum( (CAP-sigs_ref[i])**2)\n",
    "    errs.append(err)\n",
    "    \n",
    "pl.plot(bw_arr, errs)\n",
    "pl.xlabel('BW10 model (Hz)')\n",
    "\n",
    "pl.ylabel('square err')\n",
    "\n",
    "\n",
    "ind_min=np.argmin(errs)\n",
    "print(f'estimated bw10: {bw_arr[ind_min]:.0f} Hz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try more accurate estimation of i/o curve\n",
    "\n",
    "signals_proc=ntch_signals_proc\n",
    "maskingConds=ntch_maskingConds\n",
    "\n",
    "\n",
    "io_func = 'weibull'  #'sigm'\n",
    "sigm2=SigmoidIOFunc(sigm.mu.numpy(), sigm.a.numpy(), Iref=I0-20, constrained_at_Iref=True, requires_grad=True)\n",
    "\n",
    "\n",
    "# wb_cdf2=WeibullCDF_IOFunc(I0=wb_cdf.I0.numpy(),\n",
    "#     scale=wb_cdf.scale.numpy(),\n",
    "#     mmax=wb_cdf.mmax.numpy(),\n",
    "#     k=wb_cdf.k.numpy(),\n",
    "#     requires_grad=True,\n",
    "#     constrained_at_Iref=True,\n",
    "#     Iref=I0-20)\n",
    "\n",
    "wb_cdf2=WeibullCDF_IOFunc(I0=-20.,\n",
    "    scale=30.,\n",
    "    k=10.,\n",
    "    mmax=1.,\n",
    "    requires_grad=True,\n",
    "    constrained_at_Iref=True,\n",
    "    Iref=I0-20)\n",
    "\n",
    "E2=ExcitationPatterns(t2, E0, requires_grad=True)  #no non-maskable part\n",
    "BW10_0TestFunc=constant_BW10(2000, requires_grad=False)\n",
    "\n",
    "\n",
    "if io_func=='weibull':\n",
    "    E2.set_masking_model(lat_model, BW10_0TestFunc, ntch_maskingConds, wb_cdf2)\n",
    "else:\n",
    "    E2.set_masking_model(lat_model, BW10_0TestFunc, ntch_maskingConds, sigm2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def complex_multiplication(t1, t2):\n",
    "    real1, imag1 = t1[:, :, 0], t1[:, :, 1]\n",
    "    real2, imag2 = t2[:, 0], t2[:, 1]\n",
    "    return torch.stack([real1 * real2 - imag1 * imag2, real1 * imag2 + imag1 * real2], dim = -1)\n",
    "\n",
    "excs = E2.get_tensor() \n",
    "\n",
    "excs_fft = torch.rfft(excs, 1)\n",
    "ur_fft= torch.rfft(torch.tensor(u1_mat[0]), 1)\n",
    "CAPs_fft=complex_multiplication(excs_fft, ur_fft)\n",
    "CAPs = torch.irfft(CAPs_fft, 1, signal_sizes=(excs.shape[1], ))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_steps=300\n",
    "alpha=50\n",
    "\n",
    "step_verbose=20\n",
    "if io_func=='weibull':\n",
    "    pl.plot(I, wb_cdf2(torch.tensor(I)).detach().numpy(), label=f'step 0')\n",
    "else:\n",
    "    pl.plot(I, sigm2(torch.tensor(I)).detach().numpy(), label=f'step 0')\n",
    "for i in range(1, nb_steps+1):\n",
    "    \n",
    "    excs = E2.get_tensor() \n",
    "\n",
    "    excs_fft = torch.rfft(excs, 1)\n",
    "    ur_fft= torch.rfft(torch.tensor(u1_mat[0]), 1)\n",
    "    CAPs_fft=complex_multiplication(excs_fft, ur_fft)\n",
    "    CAPs = torch.irfft(CAPs_fft, 1, signal_sizes=(excs.shape[1], ))\n",
    "\n",
    "    err=torch.sum( (CAPs- torch.tensor(signals_proc) )**2 )\n",
    "    \n",
    "    err.backward()\n",
    "    \n",
    "    if io_func == 'weibull':\n",
    "        wb_cdf2.I0.data-=alpha*wb_cdf2.I0.grad\n",
    "        wb_cdf2.I0.grad.zero_()\n",
    "        wb_cdf2.scale.data-=alpha*wb_cdf2.scale.grad\n",
    "        wb_cdf2.scale.grad.zero_()  \n",
    "        wb_cdf2.k.data-=alpha*wb_cdf2.k.grad\n",
    "        wb_cdf2.k.grad.zero_()  \n",
    "        \n",
    "        if i%step_verbose==0:\n",
    "            print(f'step {i}, I0={wb_cdf2.I0:.3f}, scale={wb_cdf2.scale:.3f}, k={wb_cdf2.k:.3f},')\n",
    "    else:\n",
    "        sigm2.mu.data=sigm2.mu.data-alpha*sigm2.mu.grad\n",
    "        sigm2.mu.grad.zero_()\n",
    "        sigm2.a.data=sigm2.a.data-alpha*sigm2.a.grad\n",
    "        sigm2.a.grad.zero_()\n",
    "        \n",
    "    E2.E0_maskable.data = (1-alpha*torch.sum(E2.E0_maskable.grad))*E2.E0_maskable.data\n",
    "    E2.E0_maskable.grad.zero_()\n",
    "    \n",
    "    if io_func=='weibull':\n",
    "        if i%step_verbose==0:\n",
    "            pl.plot(I, wb_cdf2(torch.tensor(I)).detach().numpy(), label=f'step {i}')\n",
    "    else:\n",
    "        pl.plot(I, sigm2(torch.tensor(I)).detach().numpy(), label=f'step {i}')\n",
    "pl.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model\n",
    "with torch.no_grad():\n",
    "    u1=u1_mat[0]\n",
    "    pl.figure(figsize=(12,20))\n",
    "    ax_list=plotSimulatedCAPs(E2, u1, ylim=[-0.01, 0.01], max_plots=10)\n",
    "    plotSimulatedCAPs(E2, CAParray=ntch_signals_proc, axlist=ax_list, max_plots=10)\n",
    "    pl.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntch_maskerNames[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wcdf=WeibullCDF_IOFunc()\n",
    "wcdf.fit_data(I_pts, maskamount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotMaskingDegreeFunc(wcdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "E2.set_masking_model(lat_model, BW10_0TestFunc, ntch_maskingConds, wcdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
