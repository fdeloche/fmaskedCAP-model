{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "from masking import *\n",
    "from tuning import Q10RBFNet\n",
    "import json\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "import sys\n",
    "\n",
    "from rbf import RBFNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E0_distributed=True\n",
    "I0_distributed=True\n",
    "write_results=True\n",
    "expe_name='1-22' "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_func(f, beta=0.7, Q_0=2.):\n",
    "    #return log Q in function of freq f. No level dependance\n",
    "    f0 = 1000\n",
    "    return np.log10(Q_0)+beta*(torch.log10(f)-np.log10(f0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RBF NeuralNet for Q10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n=6\n",
    "#net=Q10RBFNet(n, sig=0.3)\n",
    "net=Q10RBFNet.create_from_jsonfile('RBF_params.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_gauss(x, f, c, weight, sig, log=True, mult_factor=1.):\n",
    "    arr=mult_factor*weight*torch.exp(- (x-c)**2/(2*sig)**2)\n",
    "    if log:\n",
    "        pl.plot(f, 10**arr, '--')\n",
    "    else:\n",
    "        pl.plot(f, arr, '--')\n",
    "\n",
    "def plot_Q10(label='', plot_target=False, plot_rbfs=False):\n",
    "    m=100\n",
    "    x=torch.linspace(0,1,m)\n",
    "    f = net.real_coord(x)\n",
    "\n",
    "    out=net.forward(f)\n",
    "    pl.plot(f.numpy(), 10**out.data.numpy()[:,0], label=label)\n",
    "    if plot_target:\n",
    "        target=target_func(f)\n",
    "        pl.plot(f.numpy(), 10**target, label=\"target\")\n",
    "    if plot_rbfs:\n",
    "        for i in range(net.n_centers):\n",
    "            c=net.centers[i]\n",
    "            weight=net.l2.weight[0, i]\n",
    "            with torch.no_grad():\n",
    "                plot_gauss(x, f, c, weight, net.sig)\n",
    "    #pl.xscale('log')\n",
    "    #pl.yscale('log')\n",
    "    pl.xlabel('f')\n",
    "    pl.xlim([800, 10000])\n",
    "    #pl.legend()\n",
    "    #pl.show()\n",
    "    \n",
    "plot_Q10(plot_rbfs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.centers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RBF NeuralNet for I0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_I0=6\n",
    "#net_I0=RBFNet(n_I0, sig=0.3)\n",
    "net_I0=RBFNet.create_from_jsonfile('RBF_I0_params.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CFs=[3000, 4000, 5000, 6000]\n",
    "results_folder=f'./results/fit{expe_name}-distrib/'\n",
    "#results_folder=f'./results/fit{expe_name}/'\n",
    "    \n",
    "\n",
    "CFs=[3000, 4000, 5000, 6000, 8000]\n",
    "\n",
    "I0s=[]\n",
    "\n",
    "for CF in CFs:\n",
    "    wb_cdf=WeibullCDF_IOFunc.load_from_npz(f'{results_folder}/wbcfdIO_{CF}.npz')\n",
    "    I0s.append(wb_cdf.I0)\n",
    "\n",
    "def target_func_I0(f):\n",
    "    return np.interp(f, CFs, I0s)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_I0(label='', plot_target=False, plot_rbfs=False):\n",
    "    m=100\n",
    "    x=torch.linspace(0,1,m)\n",
    "    f = net_I0.real_coord(x)\n",
    "\n",
    "    out=net_I0.forward(f)\n",
    "    pl.plot(f.numpy(), out.data.numpy()[:,0], label=label)\n",
    "    if plot_target:\n",
    "        target=target_func_I0(f)\n",
    "        pl.plot(f.numpy(), target, label=\"target\")\n",
    "    if plot_rbfs:\n",
    "        for i in range(net_I0.n_centers):\n",
    "            c=net_I0.centers[i]\n",
    "            weight=net_I0.l2.weight[0, i]\n",
    "            with torch.no_grad():\n",
    "                plot_gauss(x, f, c, weight, net_I0.sig, log=False, mult_factor=net_I0.mult_factor)\n",
    "    #pl.xscale('log')\n",
    "    #pl.yscale('log')\n",
    "    pl.xlabel('f')\n",
    "    pl.xlim([800, 10000])\n",
    "    #pl.legend()\n",
    "    #pl.show()\n",
    "    \n",
    "plot_I0(plot_rbfs=True, plot_target=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 2e-2\n",
    "lr_centers=0\n",
    "optimizer = optim.SGD([\n",
    "    {'params':net.parameters()}, \n",
    "    {'params': [net.centers], 'lr':lr_centers}], #centers \n",
    "    lr=lr, momentum=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps=100\n",
    "batch_size=8\n",
    "test_batch_size=256\n",
    "criterion = nn.MSELoss()\n",
    "verbose=True\n",
    "step_test=5 #all step_test, estimate loss \n",
    "losses=[]\n",
    "\n",
    "#mode for selectinf frequencies\n",
    "#mode='random'\n",
    "mode='fixed'\n",
    "\n",
    "f_min=800.\n",
    "f_max=15000.\n",
    "\n",
    "\n",
    "#targetfunc=partial(target_func)\n",
    "\n",
    "targetfunc=partial(target_func, beta=0.4, Q_0=1.5)\n",
    "\n",
    "f_arr=torch.tensor([1500., 2200., 3000., 4000., 5000., 6000., 8000.])\n",
    "for i in range(n_steps):\n",
    "    optimizer.zero_grad()\n",
    "    if mode =='random':\n",
    "        f=f_min+(f_max-f_min)*torch.rand((batch_size, 1), requires_grad=False)\n",
    "    else:\n",
    "        ind=torch.randint(len(f_arr), (batch_size, 1))\n",
    "        f=f_arr[ind]\n",
    "    #random_values = torch.rand(batch_size,2, requires_grad=False)\n",
    "    #I, f = net.real_coord(random_values[:,0], random_values[:,1])\n",
    "    target=targetfunc(f)    \n",
    "    target.unsqueeze_(-1)\n",
    "    out=net.forward(f, verbose=(i%step_test==0))\n",
    "    loss = criterion(target, out)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if verbose and i%step_test==0:\n",
    "        #test\n",
    "        \n",
    "        random_values = torch.rand(test_batch_size,1, requires_grad=False)\n",
    "        f = net.real_coord(random_values)\n",
    "        out=net.forward(f)\n",
    "        target=targetfunc(f)\n",
    "        target.unsqueeze_(-1)\n",
    "        loss = criterion(target, out)/test_batch_size\n",
    "        grad_norm=net.l2.weight.grad.norm()\n",
    "        losses.append(loss)\n",
    "        #print(\"ex:I={:.1f} dB, f={:.1f} kHz, estimate={:.2f}, target={:.2f}\".format(I[0].item(), f[0].item(),10**out[0].item(), 10**target[0].item()))\n",
    "        print(\"step : {}, loss: {:.5f}, grad norm: {:.3f}\".format(i, loss.data, grad_norm))\n",
    "        \n",
    "pl.figure()\n",
    "pl.title(\"MSE loss\")\n",
    "pl.plot(range(0,n_steps, step_test), losses[0::])\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "lr_centers=0\n",
    "optimizer_I0 = optim.SGD([\n",
    "    {'params':net_I0.parameters()}, \n",
    "    {'params': [net_I0.centers], 'lr':lr_centers}], #centers \n",
    "    lr=lr, momentum=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps=200\n",
    "batch_size=8\n",
    "test_batch_size=256\n",
    "criterion = nn.MSELoss()\n",
    "verbose=True\n",
    "step_test=5 #all step_test, estimate loss \n",
    "losses=[]\n",
    "\n",
    "#mode for selectinf frequencies\n",
    "mode='random'\n",
    "#mode='fixed'\n",
    "\n",
    "f_min=800.\n",
    "f_max=10000.\n",
    "\n",
    "\n",
    "targetfunc=target_func_I0\n",
    "\n",
    "f_arr=torch.tensor([1500., 2200., 3000., 4000., 5000., 6000., 8000.])\n",
    "for i in range(n_steps):\n",
    "    optimizer_I0.zero_grad()\n",
    "    if mode =='random':\n",
    "        f=f_min+(f_max-f_min)*torch.rand((batch_size, 1), requires_grad=False)\n",
    "    else:\n",
    "        ind=torch.randint(len(f_arr), (batch_size, 1))\n",
    "        f=f_arr[ind]\n",
    "    #random_values = torch.rand(batch_size,2, requires_grad=False)\n",
    "    #I, f = net.real_coord(random_values[:,0], random_values[:,1])\n",
    "    target=targetfunc(f)    \n",
    "    target=torch.tensor(target, dtype=torch.float)\n",
    "    target.unsqueeze_(-1)\n",
    "    out=net_I0.forward(f, verbose=(i%step_test==0))\n",
    "    loss = criterion(target, out)\n",
    "    loss.backward()\n",
    "    optimizer_I0.step()\n",
    "    if verbose and i%step_test==0:\n",
    "        #test\n",
    "        \n",
    "        random_values = torch.rand(test_batch_size,1, requires_grad=False)\n",
    "        f = net_I0.real_coord(random_values)\n",
    "        out=net_I0.forward(f)\n",
    "        target=targetfunc(f)\n",
    "        target=torch.tensor(target, dtype=torch.float)\n",
    "        target.unsqueeze_(-1)\n",
    "        loss = criterion(target, out)/test_batch_size\n",
    "        grad_norm=net_I0.l2.weight.grad.norm()\n",
    "        losses.append(loss)\n",
    "        #print(\"ex:I={:.1f} dB, f={:.1f} kHz, estimate={:.2f}, target={:.2f}\".format(I[0].item(), f[0].item(),10**out[0].item(), 10**target[0].item()))\n",
    "        print(\"step : {}, loss: {:.5f}, grad norm: {:.3f}\".format(i, loss.data, grad_norm))\n",
    "        \n",
    "pl.figure()\n",
    "pl.title(\"MSE loss\")\n",
    "pl.plot(range(0,n_steps, step_test), losses[0::])\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "plot_I0(plot_rbfs=True, plot_target=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distributed learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch.distributed as dist\n",
    "\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backend=dist.Backend('gloo')\n",
    "n_workers=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist.init_process_group(backend, init_method='tcp://127.0.0.1:1234', world_size=n_workers, rank=0, \n",
    "                        timeout=datetime.timedelta(0, 20))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if E0_distributed:\n",
    "    with open('E0_params.json') as f:\n",
    "        params = json.load(f)        \n",
    "        f_min=float(params['f_min'])\n",
    "        f_max=float(params['f_max'])\n",
    "        m=int(params['m'])\n",
    "\n",
    "    E0=1/2*torch.ones((m,), dtype=torch.float64)\n",
    "\n",
    "    #pl.plot(np.linspace(f_min*1e-3, f_max*1e-3, m), E0)\n",
    "    #pl.xlabel('Frequency (kHz)')\n",
    "    #pl.ylabel('Init raw excitation')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "COMMUNICATIONS\n",
    "\n",
    "-> update RBF weights Q10 (tag 7)\n",
    "[-> update RBF weights I0 (tag 17)]\n",
    "\n",
    "(at each iteration)\n",
    "<- nb_steps (0. if optim done or nb_steps)  (tag 16)\n",
    "-> update E0 (tag 8)\n",
    "-> update RBF Q10 (tag 7)\n",
    "[-> update RBF I0 (tag 17)]\n",
    "<- receive E0 grads (tag 2000 + step)\n",
    "<- receive RBF grads (tag 1000 + step)\n",
    "\n",
    "[<- receive RBF grads for I0 (tag 3000+step)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wait_handle(h, timeout=10, interval=0.02, name=''):\n",
    "    start = time.time()\n",
    "    \n",
    "        \n",
    "    #should be the normal way to go but it is bugged:\n",
    "    '''while (not h.is_completed()) and time.time() - start < timeout:\n",
    "        time.sleep(interval)\n",
    "    '''\n",
    "    try:\n",
    "        h.wait()\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "        print(f'handle [{name}] not completed before timeout')\n",
    "        \n",
    "    \n",
    "\n",
    "def wait_list_handles(l, names=None, timeout=10):\n",
    "    for i, handle in enumerate(l):\n",
    "        name = None if names is None else names[i]\n",
    "        #handle.wait()\n",
    "        wait_handle(handle, name=name, timeout=timeout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Send weights for RBF net (Q10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "send_handles=[]\n",
    "handle_names=[]\n",
    "for rank in range(1, n_workers):\n",
    "    handle=dist.isend(net.l2.weight, rank, tag=7)\n",
    "    handle_name = f'update weights RBF rank {rank}'\n",
    "    send_handles.append(handle)\n",
    "    handle_names.append(handle_name)\n",
    "\n",
    "wait_list_handles(send_handles, names=handle_names, timeout=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Send weights for RBF net (I0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "send_handles=[]\n",
    "handle_names=[]\n",
    "for rank in range(1, n_workers):\n",
    "    handle=dist.isend(net_I0.l2.weight, rank, tag=17)\n",
    "    handle_name = f'update weights RBF I0 rank {rank}'\n",
    "    send_handles.append(handle)\n",
    "    handle_names.append(handle_name)\n",
    "\n",
    "wait_list_handles(send_handles, names=handle_names, timeout=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "optim steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "it_step_plot=10\n",
    "k_it=0\n",
    "#TODO in param file?\n",
    "alpha=1.5\n",
    "alpha_E0=6\n",
    "alpha_I0=0.15\n",
    "\n",
    "nb_steps_arr=torch.ones((n_workers-1,), dtype=torch.int32)\n",
    "\n",
    "\n",
    "if E0_distributed:\n",
    "    grad_E0=torch.zeros_like(E0, dtype=torch.float64)\n",
    "grad=torch.zeros_like(net.l2.weight)\n",
    "grad_I0=torch.zeros_like(net_I0.l2.weight)\n",
    "\n",
    "pl.figure(figsize=(6, 12))\n",
    "\n",
    "\n",
    "ax1=pl.subplot(2,1,1)\n",
    "ax2=pl.subplot(2,1,2)\n",
    "while True:\n",
    "    \n",
    "    \n",
    "    optim_done_handles=[]\n",
    "    handle_names=[]\n",
    "    for rank in range(1, n_workers):\n",
    "        if nb_steps_arr[rank-1]>0:\n",
    "            optim_done_handles.append(dist.irecv(nb_steps_arr[rank-1], rank, tag=16))\n",
    "            handle_names.append(f'nb steps it {k_it} rank {rank}')\n",
    "    wait_list_handles(optim_done_handles, names=handle_names)\n",
    "    \n",
    "    if torch.count_nonzero(nb_steps_arr) == 0:\n",
    "        break\n",
    "        \n",
    "        \n",
    "    #update E0\n",
    "    if E0_distributed:   \n",
    "        send_handles=[]\n",
    "        handle_names=[]\n",
    "        for rank in range(1, n_workers):  #the other nodes update weights at start of loop\n",
    "            if nb_steps_arr[rank-1]>0:\n",
    "                send_handles.append(dist.isend(E0, rank, tag=8))\n",
    "                handle_names.append(f'update E0 it {k_it} rank {rank}')\n",
    "\n",
    "        wait_list_handles(send_handles, names=handle_names)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #update Q10\n",
    "    send_handles=[]\n",
    "    handle_names=[]\n",
    "    for rank in range(1, n_workers):  #the other nodes update weights at start of loop\n",
    "        if nb_steps_arr[rank-1]>0:\n",
    "            send_handles.append(dist.isend(net.l2.weight, rank, tag=7))\n",
    "            handle_names.append(f'update RBF weights it {k_it} rank {rank}')\n",
    "\n",
    "    wait_list_handles(send_handles, names=handle_names)\n",
    "    \n",
    "    \n",
    "    #update I0\n",
    "    if I0_distributed:\n",
    "        send_handles=[]\n",
    "        handle_names=[]\n",
    "        for rank in range(1, n_workers):  #the other nodes update weights at start of loop\n",
    "            if nb_steps_arr[rank-1]>0:\n",
    "                send_handles.append(dist.isend(net_I0.l2.weight, rank, tag=17))\n",
    "                handle_names.append(f'update RBF weights (I0) it {k_it} rank {rank}')\n",
    "\n",
    "        wait_list_handles(send_handles, names=handle_names)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    max_nb_steps=int(torch.amax(nb_steps_arr))\n",
    "                     \n",
    "    if E0_distributed:\n",
    "        for step in range(1, max_nb_steps+1):\n",
    "            for rank in range(1, n_workers): #gradients are forwarded by the other nodes\n",
    "                if step<=nb_steps_arr[rank-1]:  \n",
    "                    hand = dist.irecv(grad_E0, src=rank, tag=2000+step)\n",
    "                    wait_handle(hand, name=f'grad E0 it {k_it} step {step} rank {rank}')\n",
    "                    E0.data-=alpha_E0*grad_E0\n",
    "                    \n",
    "    if I0_distributed:\n",
    "        for step in range(1, max_nb_steps+1):\n",
    "            for rank in range(1, n_workers): #gradients are forwarded by the other nodes\n",
    "                if step<=nb_steps_arr[rank-1]:  \n",
    "                    hand = dist.irecv(grad_I0, src=rank, tag=3000+step)\n",
    "                    wait_handle(hand, name=f'grad RBF weights (I0) it {k_it} step {step} rank {rank}')\n",
    "                    net_I0.l2.weight.data-=alpha_I0*grad_I0\n",
    "                    \n",
    "    for step in range(1, max_nb_steps+1):\n",
    "        for rank in range(1, n_workers): #gradients are forwarded by the other nodes\n",
    "            if step<=nb_steps_arr[rank-1]:  \n",
    "                hand=dist.irecv(grad, src=rank, tag=1000+step)\n",
    "                wait_handle(hand, name=f'grad RBF weights it {k_it} step {step} rank {rank}')\n",
    "                net.l2.weight.data-=alpha*grad\n",
    "\n",
    "        \n",
    "    k_it+=1\n",
    "    \n",
    "    if k_it%it_step_plot==0:\n",
    "        pl.sca(ax1)\n",
    "        plot_Q10(label=f'step {k_it}')\n",
    "        pl.sca(ax2)\n",
    "        plot_I0(label=f'step {k_it}')\n",
    "        \n",
    "pl.sca(ax1) \n",
    "pl.legend()\n",
    "\n",
    "pl.sca(ax2) \n",
    "pl.legend()\n",
    "\n",
    "pl.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_Q10()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_I0(plot_target=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if write_results:    \n",
    "    m=100\n",
    "    x=torch.linspace(0,1,m)\n",
    "    f = net.real_coord(x)\n",
    "    out=net.forward(f)\n",
    "    Q10_val=10**out.data.numpy()[:,0]\n",
    "    \n",
    "    results_folder=f'./results/fit{expe_name}-distrib/'\n",
    "    np.savez(f'{results_folder}/Q10.npz', f=f.detach().numpy(), Q10=Q10_val )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
