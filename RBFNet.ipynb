{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "\n",
    "from masking import *\n",
    "from tuning import Q10RBFNet\n",
    "import json\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "import sys\n",
    "\n",
    "import os\n",
    "from rbf import RBFNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_json_file=True  #if True, loads params from distrib_params.json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_folder=None\n",
    "load_json_optim_params=False\n",
    "if load_json_file:\n",
    "    with open('distrib_params.json') as f:\n",
    "        params = json.load(f)\n",
    "        E0_distributed=params['E0_distributed']\n",
    "        I0_distributed=params['I0_distributed']\n",
    "        write_results=params[\"write_results\"]\n",
    "        expe_name=params[\"expe_name\"]\n",
    "        try:\n",
    "            results_name=params[\"results_name\"]\n",
    "            results_folder=params[\"results_folder\"]\n",
    "        except KeyError as e:\n",
    "            print('results_folder not specified, will take default value')\n",
    "        results_folder0=params[\"results_folder0\"]\n",
    "        load_json_optim_params=params['load_json_optim_params']\n",
    "        CFs=params['CFs']\n",
    "        n_workers=int(params['n_workers'])\n",
    "else:\n",
    "    n_workers=4\n",
    "    E0_distributed=True\n",
    "    I0_distributed=True\n",
    "    write_results=True\n",
    "    expe_name='1-22' \n",
    "    results_folder0=f'./results/fit{expe_name}-distrib/' #if I0_distributed, loads wb cdf params from other folder\n",
    "\n",
    "    \n",
    "#NB: Q10_distributed is considered always True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_func(f, beta=0.7, Q_0=2.):\n",
    "    #return log Q in function of freq f. No level dependance\n",
    "    f0 = 1000\n",
    "    return np.log10(Q_0)+beta*(torch.log10(f)-np.log10(f0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RBF NeuralNet for Q10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n=6\n",
    "#net=Q10RBFNet(n, sig=0.3)\n",
    "net=Q10RBFNet.create_from_jsonfile('RBF_params.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_gauss(x, f, c, weight, sig, log=True, mult_factor=1.):\n",
    "    arr=mult_factor*weight*torch.exp(- (x-c)**2/(2*sig)**2)\n",
    "    if log:\n",
    "        pl.plot(f, 10**arr, '--')\n",
    "    else:\n",
    "        pl.plot(f, arr, '--')\n",
    "\n",
    "def plot_Q10(label='', plot_target=False, plot_rbfs=False):\n",
    "    m=100\n",
    "    x=torch.linspace(0,1,m)\n",
    "    f = net.real_coord(x)\n",
    "\n",
    "    out=net.forward(f)\n",
    "    pl.plot(f.numpy(), 10**out.data.numpy()[:,0], label=label)\n",
    "    if plot_target:\n",
    "        target=target_func(f)\n",
    "        pl.plot(f.numpy(), 10**target, label=\"target\")\n",
    "    if plot_rbfs:\n",
    "        for i in range(net.n_centers):\n",
    "            c=net.centers[i]\n",
    "            weight=net.l2.weight[0, i]\n",
    "            with torch.no_grad():\n",
    "                plot_gauss(x, f, c, weight, net.sig)\n",
    "    #pl.xscale('log')\n",
    "    #pl.yscale('log')\n",
    "    pl.xlabel('f')\n",
    "    pl.xlim([800, 10000])\n",
    "    #pl.legend()\n",
    "    #pl.show()\n",
    "    \n",
    "plot_Q10(plot_rbfs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.centers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RBF NeuralNet for I0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_I0=6\n",
    "#net_I0=RBFNet(n_I0, sig=0.3)\n",
    "net_I0=RBFNet.create_from_jsonfile('RBF_I0_params.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if I0_distributed:\n",
    "    if not load_json_file:\n",
    "        #results_folder=f'./results/fit{expe_name}/'\n",
    "        CFs=[3000, 4000, 5000, 6000, 8000]\n",
    "\n",
    "    if results_folder is None:\n",
    "        results_folder=f'./results/fit{expe_name}-distrib/'\n",
    "    I0s=[]\n",
    "\n",
    "    for CF in CFs:\n",
    "\n",
    "        wb_cdf=WeibullCDF_IOFunc.load_from_npz(f'{results_folder0}/wbcfdIO_{CF}.npz')\n",
    "        I0s.append(wb_cdf.I0)\n",
    "\n",
    "    def target_func_I0(f):\n",
    "        return np.interp(f, CFs, I0s)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_I0(label='', plot_target=False, plot_rbfs=False):\n",
    "    m=100\n",
    "    x=torch.linspace(0,1,m)\n",
    "    f = net_I0.real_coord(x)\n",
    "\n",
    "    out=net_I0.forward(f)\n",
    "    pl.plot(f.numpy(), out.data.numpy()[:,0], label=label)\n",
    "    if plot_target:\n",
    "        target=target_func_I0(f)\n",
    "        pl.plot(f.numpy(), target, label=\"target\")\n",
    "    if plot_rbfs:\n",
    "        for i in range(net_I0.n_centers):\n",
    "            c=net_I0.centers[i]\n",
    "            weight=net_I0.l2.weight[0, i]\n",
    "            with torch.no_grad():\n",
    "                plot_gauss(x, f, c, weight, net_I0.sig, log=False, mult_factor=net_I0.mult_factor)\n",
    "    #pl.xscale('log')\n",
    "    #pl.yscale('log')\n",
    "    pl.xlabel('f')\n",
    "    pl.xlim([800, 10000])\n",
    "    #pl.legend()\n",
    "    #pl.show()\n",
    "\n",
    "if I0_distributed:\n",
    "    plot_I0(plot_rbfs=True, plot_target=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 2e-2\n",
    "lr_centers=0\n",
    "optimizer = optim.SGD([\n",
    "    {'params':net.parameters()}, \n",
    "    {'params': [net.centers], 'lr':lr_centers}], #centers \n",
    "    lr=lr, momentum=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps=100\n",
    "batch_size=8\n",
    "test_batch_size=256\n",
    "criterion = nn.MSELoss()\n",
    "verbose=True\n",
    "step_test=5 #all step_test, estimate loss \n",
    "losses=[]\n",
    "\n",
    "#mode for selectinf frequencies\n",
    "#mode='random'\n",
    "mode='fixed'\n",
    "\n",
    "f_min=800.\n",
    "f_max=15000.\n",
    "\n",
    "\n",
    "#targetfunc=partial(target_func)\n",
    "\n",
    "targetfunc=partial(target_func, beta=0.4, Q_0=1.5)\n",
    "\n",
    "f_arr=torch.tensor([1500., 2200., 3000., 4000., 5000., 6000., 8000.])\n",
    "for i in range(n_steps):\n",
    "    optimizer.zero_grad()\n",
    "    if mode =='random':\n",
    "        f=f_min+(f_max-f_min)*torch.rand((batch_size, 1), requires_grad=False)\n",
    "    else:\n",
    "        ind=torch.randint(len(f_arr), (batch_size, 1))\n",
    "        f=f_arr[ind]\n",
    "    #random_values = torch.rand(batch_size,2, requires_grad=False)\n",
    "    #I, f = net.real_coord(random_values[:,0], random_values[:,1])\n",
    "    target=targetfunc(f)    \n",
    "    target.unsqueeze_(-1)\n",
    "    out=net.forward(f, verbose=(i%step_test==0))\n",
    "    loss = criterion(target, out)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if verbose and i%step_test==0:\n",
    "        #test\n",
    "        \n",
    "        random_values = torch.rand(test_batch_size,1, requires_grad=False)\n",
    "        f = net.real_coord(random_values)\n",
    "        out=net.forward(f)\n",
    "        target=targetfunc(f)\n",
    "        target.unsqueeze_(-1)\n",
    "        loss = criterion(target, out)/test_batch_size\n",
    "        grad_norm=net.l2.weight.grad.norm()\n",
    "        losses.append(loss.detach().numpy())\n",
    "        #print(\"ex:I={:.1f} dB, f={:.1f} kHz, estimate={:.2f}, target={:.2f}\".format(I[0].item(), f[0].item(),10**out[0].item(), 10**target[0].item()))\n",
    "        print(\"step : {}, loss: {:.5f}, grad norm: {:.3f}\".format(i, loss.data, grad_norm))\n",
    "        \n",
    "pl.figure()\n",
    "pl.title(\"MSE loss\")\n",
    "pl.plot(range(0,n_steps, step_test), losses[0::])\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 1e-3\n",
    "lr_centers=0\n",
    "optimizer_I0 = optim.SGD([\n",
    "    {'params':net_I0.parameters()}, \n",
    "    {'params': [net_I0.centers], 'lr':lr_centers}], #centers \n",
    "    lr=lr, momentum=0.9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if I0_distributed:\n",
    "    n_steps=200\n",
    "    batch_size=8\n",
    "    test_batch_size=256\n",
    "    criterion = nn.MSELoss()\n",
    "    verbose=True\n",
    "    step_test=5 #all step_test, estimate loss \n",
    "    losses=[]\n",
    "\n",
    "    #mode for selectinf frequencies\n",
    "    mode='random'\n",
    "    #mode='fixed'\n",
    "\n",
    "    f_min=800.\n",
    "    f_max=10000.\n",
    "\n",
    "\n",
    "    targetfunc=target_func_I0\n",
    "\n",
    "    f_arr=torch.tensor([1500., 2200., 3000., 4000., 5000., 6000., 8000.])\n",
    "    for i in range(n_steps):\n",
    "        optimizer_I0.zero_grad()\n",
    "        if mode =='random':\n",
    "            f=f_min+(f_max-f_min)*torch.rand((batch_size, 1), requires_grad=False)\n",
    "        else:\n",
    "            ind=torch.randint(len(f_arr), (batch_size, 1))\n",
    "            f=f_arr[ind]\n",
    "        #random_values = torch.rand(batch_size,2, requires_grad=False)\n",
    "        #I, f = net.real_coord(random_values[:,0], random_values[:,1])\n",
    "        target=targetfunc(f)    \n",
    "        target=torch.tensor(target, dtype=torch.float)\n",
    "        target.unsqueeze_(-1)\n",
    "        out=net_I0.forward(f, verbose=(i%step_test==0))\n",
    "        loss = criterion(target, out)\n",
    "        loss.backward()\n",
    "        optimizer_I0.step()\n",
    "        if verbose and i%step_test==0:\n",
    "            #test\n",
    "\n",
    "            random_values = torch.rand(test_batch_size,1, requires_grad=False)\n",
    "            f = net_I0.real_coord(random_values)\n",
    "            out=net_I0.forward(f)\n",
    "            target=targetfunc(f)\n",
    "            target=torch.tensor(target, dtype=torch.float)\n",
    "            target.unsqueeze_(-1)\n",
    "            loss = criterion(target, out)/test_batch_size\n",
    "            grad_norm=net_I0.l2.weight.grad.norm()\n",
    "            losses.append(loss.detach().numpy())\n",
    "            #print(\"ex:I={:.1f} dB, f={:.1f} kHz, estimate={:.2f}, target={:.2f}\".format(I[0].item(), f[0].item(),10**out[0].item(), 10**target[0].item()))\n",
    "            print(\"step : {}, loss: {:.5f}, grad norm: {:.3f}\".format(i, loss.data, grad_norm))\n",
    "\n",
    "    pl.figure()\n",
    "    pl.title(\"MSE loss\")\n",
    "    pl.plot(range(0,n_steps, step_test), losses[0::])\n",
    "    pl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if I0_distributed: \n",
    "    plot_I0(plot_rbfs=True, plot_target=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distributed learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch.distributed as dist\n",
    "\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backend=dist.Backend('gloo')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist.init_process_group(backend, init_method='tcp://127.0.0.1:1234', world_size=n_workers, rank=0, \n",
    "                        timeout=datetime.timedelta(0, 80))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if E0_distributed:\n",
    "    with open('E0_params.json') as f:\n",
    "        params = json.load(f)        \n",
    "        f_min=float(params['f_min'])\n",
    "        f_max=float(params['f_max'])\n",
    "        m=int(params['m'])\n",
    "\n",
    "    E0=1/2*torch.ones((m,), dtype=torch.float64)\n",
    "\n",
    "    #pl.plot(np.linspace(f_min*1e-3, f_max*1e-3, m), E0)\n",
    "    #pl.xlabel('Frequency (kHz)')\n",
    "    #pl.ylabel('Init raw excitation')"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "COMMUNICATIONS\n",
    "\n",
    "-> update RBF weights Q10 (tag 7)\n",
    "[-> update RBF weights I0 (tag 17)]\n",
    "<- receive norm factors (tag 99) for E0\n",
    "\n",
    "(at each iteration)\n",
    "<- nb_steps (0. if optim done or nb_steps)  (tag 16)\n",
    "-> update E0 (tag 8)\n",
    "-> update RBF Q10 (tag 7)\n",
    "[-> update RBF I0 (tag 17)]\n",
    "<- receive E0 grads (tag 2000 + step)\n",
    "<- receive RBF grads (tag 1000 + step)\n",
    "\n",
    "[<- receive RBF grads for I0 (tag 3000+step)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wait_handle(h, timeout=10, interval=0.02, name=''):\n",
    "    start = time.time()\n",
    "    \n",
    "        \n",
    "    #should be the normal way to go but it is bugged:\n",
    "    '''while (not h.is_completed()) and time.time() - start < timeout:\n",
    "        time.sleep(interval)\n",
    "    '''\n",
    "    try:\n",
    "        h.wait()\n",
    "    except RuntimeError as e:\n",
    "        print(e)\n",
    "        print(f'handle [{name}] not completed before timeout')\n",
    "        \n",
    "    \n",
    "\n",
    "def wait_list_handles(l, names=None, timeout=10):\n",
    "    for i, handle in enumerate(l):\n",
    "        name = None if names is None else names[i]\n",
    "        #handle.wait()\n",
    "        wait_handle(handle, name=name, timeout=timeout)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Send weights for RBF net (Q10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "send_handles=[]\n",
    "handle_names=[]\n",
    "for rank in range(1, n_workers):\n",
    "    handle=dist.isend(net.l2.weight, rank, tag=7)\n",
    "    handle_name = f'update weights RBF rank {rank}'\n",
    "    send_handles.append(handle)\n",
    "    handle_names.append(handle_name)\n",
    "\n",
    "wait_list_handles(send_handles, names=handle_names, timeout=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Send weights for RBF net (I0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if I0_distributed:\n",
    "    send_handles=[]\n",
    "    handle_names=[]\n",
    "    for rank in range(1, n_workers):\n",
    "        handle=dist.isend(net_I0.l2.weight, rank, tag=17)\n",
    "        handle_name = f'update weights RBF I0 rank {rank}'\n",
    "        send_handles.append(handle)\n",
    "        handle_names.append(handle_name)\n",
    "\n",
    "    wait_list_handles(send_handles, names=handle_names, timeout=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "optim params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_json_optim_params:\n",
    "    \n",
    "    if os.path.exists(f'optim_params_{expe_name}.json'):\n",
    "        optim_params_filename=f'optim_params_{expe_name}.json'\n",
    "    else:\n",
    "        optim_params_filename='optim_params.json'\n",
    "    \n",
    "    with open(optim_params_filename) as f:\n",
    "        dic_params=json.load(f)\n",
    "    \n",
    "    #n_it=dic_params['n_it'] #not used as sent by other nodes\n",
    "    #nb_steps=dic_params['nb_steps'] #not used as sent by other nodes\n",
    "    #n_dim=dic_params['n_dim'] #proj done by other nodes\n",
    "    step_values=dic_params['alpha']\n",
    "    alpha_I0=float(step_values['I0RBFweights'])\n",
    "\n",
    "    alpha=alpha_Q10=float(step_values['Q10RBFweights'])\n",
    "    \n",
    "    alpha_E0=float(step_values['E0'])\n",
    "    n_dim=int(dic_params['n_dim'])\n",
    "else:\n",
    "    alpha=alpha_Q10=1.5\n",
    "    alpha_E0=6\n",
    "    alpha_I0=0.15\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "receive norm factor for E0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "norm_factor_arr=torch.ones((n_workers-1,), dtype=torch.float64)\n",
    "\n",
    "\n",
    "if E0_distributed:\n",
    "    norm_factor_handles=[]\n",
    "    handle_names=[]\n",
    "    for rank in range(1, n_workers):\n",
    "        norm_factor_handles.append(dist.irecv(norm_factor_arr[rank-1], rank, tag=99))\n",
    "        handle_names.append(f'receive norm factor rank {rank}')\n",
    "    wait_list_handles(norm_factor_handles, names=handle_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "find E0 to match norm factors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#objective: match 1/norm_factor_arr\n",
    "if E0_distributed:\n",
    "    filter_fft=torch.zeros_like(torch.fft.rfft(E0))\n",
    "    filter_fft[0:n_dim]=1\n",
    "\n",
    "    def proj_fft2(grad):  #from optim.py\n",
    "        grad_fft=torch.fft.rfft(grad)\n",
    "        grad_fft*=filter_fft\n",
    "        return torch.fft.irfft(grad_fft, n=len(grad))\n",
    "\n",
    "    E0_2=E0.clone().detach().requires_grad_(True)\n",
    "    inds=[int(CF/(f_max-f_min)*m) for CF in CFs]\n",
    "    optimizer_E0 = optim.SGD([E0_2], lr=10, momentum=0.2)\n",
    "    for i in range(40):\n",
    "        optimizer_E0.zero_grad()\n",
    "        \n",
    "        err=torch.sum((1/norm_factor_arr-E0_2[inds])**2)\n",
    "        err.backward()\n",
    "        optimizer_E0.step()\n",
    "        E0_2.data=proj_fft2(E0_2)\n",
    "        if i%5==0:\n",
    "            pl.plot(np.linspace(f_min, f_max, m), E0_2.clone().detach().numpy(), label=i)\n",
    "    \n",
    "    pl.plot(CFs, 1/norm_factor_arr, '+', color='blue')\n",
    "    pl.legend()\n",
    "    pl.title('Find E0 init')\n",
    "    \n",
    "    E0.data=E0_2.data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "optim loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "it_step_plot=10\n",
    "k_it=0\n",
    "    \n",
    "nb_steps_arr=torch.ones((n_workers-1,), dtype=torch.int32)\n",
    "\n",
    "\n",
    "if E0_distributed:\n",
    "    grad_E0=torch.zeros_like(E0, dtype=torch.float64)\n",
    "grad=torch.zeros_like(net.l2.weight)\n",
    "grad_I0=torch.zeros_like(net_I0.l2.weight)\n",
    "\n",
    "pl.figure(figsize=(6, 12))\n",
    "\n",
    "\n",
    "ax1=pl.subplot(2,1,1)\n",
    "ax2=pl.subplot(2,1,2)\n",
    "while True:\n",
    "    \n",
    "    \n",
    "    optim_done_handles=[]\n",
    "    handle_names=[]\n",
    "    for rank in range(1, n_workers):\n",
    "        if nb_steps_arr[rank-1]>0:\n",
    "            optim_done_handles.append(dist.irecv(nb_steps_arr[rank-1], rank, tag=16))\n",
    "            handle_names.append(f'nb steps it {k_it} rank {rank}')\n",
    "    wait_list_handles(optim_done_handles, names=handle_names)\n",
    "    \n",
    "    if torch.count_nonzero(nb_steps_arr) == 0:\n",
    "        break\n",
    "        \n",
    "        \n",
    "    #update E0\n",
    "    if E0_distributed:   \n",
    "        send_handles=[]\n",
    "        handle_names=[]\n",
    "        for rank in range(1, n_workers):  #the other nodes update weights at start of loop\n",
    "            if nb_steps_arr[rank-1]>0:\n",
    "                send_handles.append(dist.isend(E0, rank, tag=8))\n",
    "                handle_names.append(f'update E0 it {k_it} rank {rank}')\n",
    "\n",
    "        wait_list_handles(send_handles, names=handle_names)\n",
    "    \n",
    "    \n",
    "    \n",
    "    #update Q10\n",
    "    send_handles=[]\n",
    "    handle_names=[]\n",
    "    for rank in range(1, n_workers):  #the other nodes update weights at start of loop\n",
    "        if nb_steps_arr[rank-1]>0:\n",
    "            send_handles.append(dist.isend(net.l2.weight, rank, tag=7))\n",
    "            handle_names.append(f'update RBF weights it {k_it} rank {rank}')\n",
    "\n",
    "    wait_list_handles(send_handles, names=handle_names)\n",
    "    \n",
    "    \n",
    "    #update I0\n",
    "    if I0_distributed:\n",
    "        send_handles=[]\n",
    "        handle_names=[]\n",
    "        for rank in range(1, n_workers):  #the other nodes update weights at start of loop\n",
    "            if nb_steps_arr[rank-1]>0:\n",
    "                send_handles.append(dist.isend(net_I0.l2.weight, rank, tag=17))\n",
    "                handle_names.append(f'update RBF weights (I0) it {k_it} rank {rank}')\n",
    "\n",
    "        wait_list_handles(send_handles, names=handle_names)\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    max_nb_steps=int(torch.amax(nb_steps_arr))\n",
    "                     \n",
    "    if E0_distributed:\n",
    "        for step in range(1, max_nb_steps+1):\n",
    "            for rank in range(1, n_workers): #gradients are forwarded by the other nodes\n",
    "                if step<=nb_steps_arr[rank-1]:  \n",
    "                    hand = dist.irecv(grad_E0, src=rank, tag=2000+step)\n",
    "                    wait_handle(hand, name=f'grad E0 it {k_it} step {step} rank {rank}')\n",
    "                    E0.data-=alpha_E0*grad_E0\n",
    "                    \n",
    "    if I0_distributed:\n",
    "        for step in range(1, max_nb_steps+1):\n",
    "            for rank in range(1, n_workers): #gradients are forwarded by the other nodes\n",
    "                if step<=nb_steps_arr[rank-1]:  \n",
    "                    hand = dist.irecv(grad_I0, src=rank, tag=3000+step)\n",
    "                    wait_handle(hand, name=f'grad RBF weights (I0) it {k_it} step {step} rank {rank}')\n",
    "                    net_I0.l2.weight.data-=alpha_I0*grad_I0\n",
    "                    \n",
    "    for step in range(1, max_nb_steps+1):\n",
    "        for rank in range(1, n_workers): #gradients are forwarded by the other nodes\n",
    "            if step<=nb_steps_arr[rank-1]:  \n",
    "                hand=dist.irecv(grad, src=rank, tag=1000+step)\n",
    "                wait_handle(hand, name=f'grad RBF weights it {k_it} step {step} rank {rank}')\n",
    "                net.l2.weight.data-=alpha*grad\n",
    "\n",
    "        \n",
    "    k_it+=1\n",
    "    \n",
    "    if k_it%it_step_plot==0:\n",
    "        pl.sca(ax1)\n",
    "        plot_Q10(label=f'step {k_it}')\n",
    "        if I0_distributed:\n",
    "            pl.sca(ax2)\n",
    "            plot_I0(label=f'step {k_it}')\n",
    "        \n",
    "pl.sca(ax1) \n",
    "pl.legend()\n",
    "\n",
    "pl.sca(ax2) \n",
    "pl.legend()\n",
    "\n",
    "pl.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_Q10()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if I0_distributed:\n",
    "    plot_I0(plot_target=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if write_results:    \n",
    "    m=100\n",
    "    x=torch.linspace(0,1,m)\n",
    "    f = net.real_coord(x)\n",
    "    out=net.forward(f)\n",
    "    Q10_val=10**out.data.numpy()[:,0]\n",
    "    \n",
    "    np.savez(f'{results_folder}/Q10.npz', f=f.detach().numpy(), Q10=Q10_val )\n",
    "    \n",
    "    np.savez(f'{results_folder}/Q10_RBF_weights.npz',weights=net.l2.weight.data )\n",
    "    \n",
    "    \n",
    "    if I0_distributed:\n",
    "            m=100\n",
    "            x=torch.linspace(0,1,m)\n",
    "            f = net_I0.real_coord(x)\n",
    "            out=net_I0.forward(f)\n",
    "            I0_val=out.data.numpy()[:,0]\n",
    "\n",
    "            np.savez(f'{results_folder}/I0_from_RBF.npz', f=f.detach().numpy(), I0=I0_val )\n",
    "            np.savez(f'{results_folder}/I0_RBF_weights.npz', weights=net_I0.l2.weight.data )\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
