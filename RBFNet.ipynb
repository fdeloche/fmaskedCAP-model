{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as pl\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "from tuning import Q10RBFNet\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E0_distributed=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Target functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def target_func(f, beta=0.7, Q_0=2.):\n",
    "    #return log Q in function of freq f. No level dependance\n",
    "    f0 = 1000\n",
    "    return np.log10(Q_0)+beta*(torch.log10(f)-np.log10(f0))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RBF NeuralNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n=6\n",
    "#net=Q10RBFNet(n, sig=0.3)\n",
    "net=Q10RBFNet.create_from_jsonfile('RBF_params.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def plot_gauss(x, f, c, weight, sig):\n",
    "    arr=weight*torch.exp(- (x-c)**2/(2*sig)**2)\n",
    "    pl.plot(f, 10**arr, '--')\n",
    "\n",
    "def plot_Q10(label='', plot_target=False, plot_rbfs=False):\n",
    "    m=100\n",
    "    x=torch.linspace(0,1,m)\n",
    "    f = net.real_coord(x)\n",
    "\n",
    "    out=net.forward(f)\n",
    "    pl.plot(f.numpy(), 10**out.data.numpy()[:,0], label=label)\n",
    "    if plot_target:\n",
    "        target=target_func(f)\n",
    "        pl.plot(f.numpy(), 10**target, label=\"target\")\n",
    "    if plot_rbfs:\n",
    "        for i in range(net.n_centers):\n",
    "            c=net.centers[i]\n",
    "            weight=net.l2.weight[0, i]\n",
    "            with torch.no_grad():\n",
    "                plot_gauss(x, f, c, weight, net.sig)\n",
    "    #pl.xscale('log')\n",
    "    #pl.yscale('log')\n",
    "    pl.xlabel('f')\n",
    "    pl.xlim([800, 10000])\n",
    "    #pl.legend()\n",
    "    #pl.show()\n",
    "    \n",
    "plot_Q10(plot_rbfs=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.centers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 2e-2\n",
    "lr_centers=0\n",
    "optimizer = optim.SGD([\n",
    "    {'params':net.parameters()}, \n",
    "    {'params': [net.centers], 'lr':lr_centers}], #centers \n",
    "    lr=lr, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_steps=100\n",
    "batch_size=8\n",
    "test_batch_size=256\n",
    "criterion = nn.MSELoss()\n",
    "verbose=True\n",
    "step_test=5 #all step_test, estimate loss \n",
    "losses=[]\n",
    "\n",
    "#mode for selectinf frequencies\n",
    "#mode='random'\n",
    "mode='fixed'\n",
    "\n",
    "f_min=800.\n",
    "f_max=15000.\n",
    "\n",
    "\n",
    "#targetfunc=partial(target_func)\n",
    "\n",
    "targetfunc=partial(target_func, beta=0.4, Q_0=1.5)\n",
    "\n",
    "f_arr=torch.tensor([1500., 2200., 3000., 4000., 5000., 6000., 8000.])\n",
    "for i in range(n_steps):\n",
    "    optimizer.zero_grad()\n",
    "    if mode =='random':\n",
    "        f=f_min+(f_max-f_min)*torch.rand((batch_size, 1), requires_grad=False)\n",
    "    else:\n",
    "        ind=torch.randint(len(f_arr), (batch_size, 1))\n",
    "        f=f_arr[ind]\n",
    "    #random_values = torch.rand(batch_size,2, requires_grad=False)\n",
    "    #I, f = net.real_coord(random_values[:,0], random_values[:,1])\n",
    "    target=targetfunc(f)    \n",
    "    target.unsqueeze_(-1)\n",
    "    out=net.forward(f, verbose=(i%step_test==0))\n",
    "    loss = criterion(target, out)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    if verbose and i%step_test==0:\n",
    "        #test\n",
    "        \n",
    "        random_values = torch.rand(test_batch_size,1, requires_grad=False)\n",
    "        f = net.real_coord(random_values)\n",
    "        out=net.forward(f)\n",
    "        target=targetfunc(f)\n",
    "        target.unsqueeze_(-1)\n",
    "        loss = criterion(target, out)/test_batch_size\n",
    "        grad_norm=net.l2.weight.grad.norm()\n",
    "        losses.append(loss)\n",
    "        #print(\"ex:I={:.1f} dB, f={:.1f} kHz, estimate={:.2f}, target={:.2f}\".format(I[0].item(), f[0].item(),10**out[0].item(), 10**target[0].item()))\n",
    "        print(\"step : {}, loss: {:.5f}, grad norm: {:.3f}\".format(i, loss.data, grad_norm))\n",
    "        \n",
    "pl.figure()\n",
    "pl.title(\"MSE loss\")\n",
    "pl.plot(range(0,n_steps, step_test), losses[0::])\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distributed learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch.distributed as dist\n",
    "\n",
    "from datetime import timedelta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "backend=dist.Backend('GLOO')\n",
    "n_workers=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist.init_process_group(backend, init_method='tcp://127.0.0.1:1234', world_size=n_workers, rank=0)  "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "f0=torch.tensor(1000.)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for rank in range(1, n_workers):\n",
    "    print(dist.recv(f0, src=rank, tag=1))"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "f0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net.l2.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if E0_distributed:\n",
    "    with open('E0_params.json') as f:\n",
    "        params = json.load(f)        \n",
    "        f_min=float(params['f_min'])\n",
    "        f_max=float(params['f_max'])\n",
    "        m=int(params['m'])\n",
    "\n",
    "    E0=1/2*torch.ones((m,), dtype=torch.float64)\n",
    "\n",
    "    #pl.plot(np.linspace(f_min*1e-3, f_max*1e-3, m), E0)\n",
    "    #pl.xlabel('Frequency (kHz)')\n",
    "    #pl.ylabel('Init raw excitation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_E0=torch.zeros_like(E0, dtype=torch.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_E0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for rank in range(1, n_workers):\n",
    "    dist.send(net.l2.weight, rank, tag=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_it=1 #100\n",
    "nb_steps=1 #5\n",
    "tot_steps=  n_it*nb_steps  #normally 3x but count only steps for Q10\n",
    "it_step_plot=10\n",
    "\n",
    "alpha=3\n",
    "alpha_E0=3\n",
    "\n",
    "if E0_distributed:\n",
    "    grad_E0=torch.zeros_like(E0, dtype=torch.float64)\n",
    "grad=torch.zeros_like(net.l2.weight)\n",
    "\n",
    "for k_it in range(n_it):\n",
    "    for rank in range(1, n_workers):  #the other nodes update weights at start of loop\n",
    "        if E0_distributed:   \n",
    "            dist.send(E0, rank, tag=8)\n",
    "        dist.send(net.l2.weight, rank, tag=7)\n",
    "        \n",
    "    if E0_distributed:\n",
    "        for step in range(nb_steps):\n",
    "            for rank in range(1, n_workers): #gradients are forwarded by the other nodes\n",
    "                dist.recv(grad_E0, src=rank, tag=2)\n",
    "                E0.data-=alpha_E0*grad_E0\n",
    "                            \n",
    "    for step in range(nb_steps):\n",
    "        for rank in range(1, n_workers): #gradients are forwarded by the other nodes\n",
    "            dist.recv(grad, src=rank, tag=1)\n",
    "            net.l2.weight.data-=alpha*grad\n",
    "    if k_it%it_step_plot==0:\n",
    "        plot_Q10(label=f'step {k_it}')\n",
    "    \n",
    "        \n",
    "pl.legend()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_Q10()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch",
   "language": "python",
   "name": "torch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
